{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from lxml import html\n",
    "import requests\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Base URL\n",
    "base_url = \"http://www.olympedia.org/athletes/\"\n",
    "ath_data = []\n",
    "ath_seen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014971033732096354\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# (1, 30000)\n",
    "for ath_num in range(135778, 135779):\n",
    "    url = base_url + str(ath_num)\n",
    "    if ath_num % 1000 == 0:\n",
    "        print(url)\n",
    "    response = requests.get(url)\n",
    "    tree = html.document_fromstring(response.text)\n",
    "\n",
    "    page_not_found = False\n",
    "    while(True):\n",
    "        if len(tree.xpath(\"//table[@class='biodata']\")) == 0:\n",
    "            if \"Rate Limit Exceeded\" in response.text:\n",
    "                print(str(ath_num) + \" - RATE LIMIT EXCEEDED\")\n",
    "                time.sleep(60)\n",
    "                response = requests.get(url)\n",
    "                tree = html.document_fromstring(response.text)\n",
    "            else:\n",
    "                print(str(ath_num) + \" - PAGE NOT FOUND\")\n",
    "                page_not_found = True\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if page_not_found == True:\n",
    "        continue\n",
    "\n",
    "    if len(tree.xpath(\"//td[contains(., 'Competed in Olympic Games')]\")) == 0:\n",
    "        print(str(ath_num) + \" - NOT OLYMPIC ATHLETE\")\n",
    "        continue\n",
    "\n",
    "    ath_seen += 1\n",
    "    ath_info = {}\n",
    "\n",
    "    # Name\n",
    "    ath_info[\"Name\"] = tree.xpath(\"//h1\")[0].text_content().strip()\n",
    "\n",
    "    bio = tree.xpath(\"//table[@class='biodata']\")[0]\n",
    "    # Sex\n",
    "    tr = bio.xpath(\"tr[contains(., 'Sex')]\")\n",
    "    if len(tr) == 0:\n",
    "        print(str(ath_num) + \" - NO SEX\")\n",
    "        ath_info[\"Sex\"] = \"\"\n",
    "    else:\n",
    "        sex = tr[0].text_content().replace(\"Sex\", \"\")\n",
    "        ath_info[\"Sex\"] = sex\n",
    "    # Birth\n",
    "    ath_info[\"Birth\"] = \"\"\n",
    "    tr = bio.xpath(\"tr[contains(., 'Born')]\")\n",
    "    if len(tr) == 0:\n",
    "        print(str(ath_num) + \" - NO BIRTH\")\n",
    "    else:\n",
    "        s = re.search(r\"\\d{4}\", tr[0].text_content())\n",
    "        if s:\n",
    "            ath_info[\"Birth\"] = s.group(0)\n",
    "\n",
    "    # Fetch Results\n",
    "    rows = tree.xpath(\"//table[@class='table table-striped'][1]//tbody/tr\")\n",
    "    results = []\n",
    "    cur_games = \"\"\n",
    "    cur_sport = \"\"\n",
    "    cur_nat = \"\"\n",
    "    for r in rows:\n",
    "        result = {}\n",
    "        entries = r.xpath(\"td\")\n",
    "        assert len(entries) == 8\n",
    "        # Games\n",
    "        s = \" \".join(entries[0].text_content().split())\n",
    "        if s != \"\":\n",
    "            cur_games = s\n",
    "        result[\"Games\"] = cur_games\n",
    "        # Sport\n",
    "        s = \" \".join(entries[1].text_content().split())\n",
    "        if s != \"\":\n",
    "            cur_sport = s\n",
    "        result[\"Sport\"] = cur_sport\n",
    "        # Event\n",
    "        s = \" \".join(entries[2].text_content().split())\n",
    "        result[\"Event\"] = s\n",
    "        # Status\n",
    "        s = \" \".join(entries[3].text_content().split())\n",
    "        result[\"Status\"] = s\n",
    "        # Team (For Team Events)\n",
    "        s = \" \".join(entries[4].text_content().split())\n",
    "        result[\"Team\"] = s\n",
    "        # Pos\n",
    "        s = \" \".join(entries[5].text_content().split())\n",
    "        result[\"Pos\"] = s\n",
    "        # Medal\n",
    "        s = \" \".join(entries[6].text_content().split())\n",
    "        result[\"Medal\"] = s\n",
    "        # Nat\n",
    "        s = \" \".join(entries[7].text_content().replace(\"Representing\",\"\").split())\n",
    "        if s != \"\":\n",
    "            cur_nat = s\n",
    "        result[\"Nat\"] = cur_nat\n",
    "        results.append(result)\n",
    "    ath_info[\"Results\"] = results\n",
    "    ath_data.append(ath_info)\n",
    "        \n",
    "end = time.time()\n",
    "print((end - start)/60)\n",
    "print(ath_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    " \n",
    "# Write CSV\n",
    "f = codecs.open(\"../data/athletes_test\"+\".txt\", \"w\", \"utf-8\")\n",
    "f.write(\"Name\\tSex\\tBirth\\tGames\\tSport\\tEvent\\tStatus\\tTeam\\tPos\\tMedal\\tNat\\n\")\n",
    "\n",
    "for ath in ath_data:\n",
    "    results = ath[\"Results\"]\n",
    "    for r in results:\n",
    "        f.write( \"\\t\".join([ath[\"Name\"], ath[\"Sex\"], ath[\"Birth\"], r[\"Games\"], r[\"Sport\"], r[\"Event\"], r[\"Status\"], r[\"Team\"], r[\"Pos\"], r[\"Medal\"], r[\"Nat\"]]) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
